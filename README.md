<h1 align="center">üåü Pr√°ctica 3 - Visi√≥n por Computador (Curso 2024/2025)</h1>

<img align="left" width="200" height="180" src="imagenes/gitcat.gif"></a>
Se han completado todas las tareas solicitadas de la **Pr√°ctica 3** para la asignatura **Visi√≥n por Computador**. Detecci√≥n de formas.

*Trabajo realizado por*:

[![GitHub](https://img.shields.io/badge/GitHub-Heliot%20J.%20Segura%20Gonzalez-orange?style=flat-square&logo=github)](https://github.com/kratoscordoba7)

[![GitHub](https://img.shields.io/badge/GitHub-Alejandro%20D.%20Arzola%20Saavedra%20-black?style=flat-square&logo=github)](https://github.com/AlejandroDavidArzolaSaavedra)

## üõ†Ô∏è Librer√≠as Utilizadas

[![NumPy](https://img.shields.io/badge/NumPy-%23013243?style=for-the-badge&logo=numpy)](Link_To_Your_NumPy_Page)
[![OpenCV](https://img.shields.io/badge/OpenCV-%23FD8C00?style=for-the-badge&logo=opencv)](Link_To_Your_OpenCV_Page)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-%43FF6400?style=for-the-badge&logo=matplotlib&logoColor=white)](Link_To_Your_Matplotlib_Page)
[![Scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](Link_To_Your_ScikitLearn_Page)
[![Seaborn](https://img.shields.io/badge/Seaborn-%2304AAE0?style=for-the-badge&logo=seaborn&logoColor=white)](Link_To_Your_Seaborn_Page)

---
## üöÄ C√≥mo empezar

Para comenzar con el proyecto, sigue estos pasos:

> [!NOTE]  
> Debes situarte en un environment configurado como se defini√≥ en el cuaderno de la pr√°ctica 1 de [otsedom](https://github.com/otsedom/otsedom.github.io/blob/main/VC/P1/README.md#111-comandos-basicos-de-anaconda) y el de la pr√°ctica 3 de [otsedom](https://github.com/otsedom/otsedom.github.io/blob/main/VC/P3/README.md).

### Paso 1: Abrir VSCode y situarse en el directorio:
   
   ```bash
   C:\Users\TuNombreDeUsuario\anaconda3\envs\VCP3
   ```

### Paso 2: Clonar y trabajar en el proyecto localmente (VS Code)
1. **Clona el repositorio**: Ejecuta el siguiente comando en tu terminal para clonar el repositorio:
   ```bash
   git clone https://github.com/kratoscordoba7/VCP3.git
   ```
2. Una vez clonado, todos los archivos han de estar situados en el environment del paso 1

### Paso 3: Abrir Anaconda prompt y activar el enviroment:
   ```bash
   conda activate NombreDeTuEnvironment
   ```
Tras estos pasos deber√≠a poder ejecutar el proyecto localmente

---

<h2 align="center">üìã Tareas</h2>

### Tarea 1 Detectar monedas

Todos los objetos de inter√©s en la imagen son circulares, en concreto monedas de la UE. Tras mostrar diversas aproximaciones para obtener sus contornos, el reto o tarea consiste en determinar la cantidad de dinero presente en la imagen.

Comenzamos con una primera aproximaci√≥n basada en los di√°metros est√°ndar de las monedas de la UE. Utilizamos la transformada de Hough para detectar c√≠rculos en la imagen. En esta etapa inicial, el usuario puede hacer clic en cualquier moneda dentro de la imagen para identificarla. Por ejemplo, en la siguiente imagen:

<div align="center">
   <img src="imagenes/moneda.png" width="180" height="300">
</div>

En este caso, el usuario ha seleccionado la moneda de 1 euro, y la informaci√≥n que se muestra es la siguiente:

- N√∫mero de monedas en la imagen: 8
- Di√°metro seleccionado en mil√≠metros: 22.27
- Di√°metro seleccionado en p√≠xeles: 175
- Moneda identificada: 1 euro

> [!IMPORTANT]  
> Es importante tener en cuenta que las fotos pueden tomarse a diferentes distancias de las monedas, por lo que las medidas obtenidas son aproximadas y pueden no ser exactas. Aunque el modelo funciona bien en este caso espec√≠fico, su precisi√≥n depende de la calidad de la foto y de las circunstancias en las que fue tomada, siendo m√°s efectivo en im√°genes con poco ruido.

Un fragmento del c√≥digo utilizado para identificar la moneda se basa en la comparaci√≥n entre el di√°metro est√°ndar y el di√°metro detectado en la imagen. El algoritmo realiza una b√∫squeda simple que compara el di√°metro medido en la imagen con el estandar de la UE. La moneda con la menor diferencia es considerada la m√°s probable.

```python
def identificar_moneda(diametro_mm):
    moneda_mas_cercana = None
    diferencia_minima = float('inf') 
    for nombre, info in monedas_info.items():
        diferencia = abs(diametro_mm - info["di√°metro"])
        if diferencia < diferencia_minima:
            diferencia_minima = diferencia
            moneda_mas_cercana = nombre
    return moneda_mas_cercana
```

Como siguiente paso, queremos que el sistema no solo sea capaz de diferenciar las monedas, sino que tambi√©n calcule el valor total de las mismas, similar al funcionamiento de un cajero autom√°tico. En la siguiente imagen se puede ver este proceso en acci√≥n:

<div align="center">
   <img src="imagenes/moneda2.png" width="180" height="300">
</div>

El resultado obtenido fue el siguiente:

- N√∫mero de monedas: 8
- Valor total: 3,88 ‚Ç¨

> [!IMPORTANT]  
> La imagen utilizada tiene un fondo blanco y se tom√≥ desde un √°ngulo favorable y a una distancia cercana, lo que permite obtener un resultado muy preciso en este caso.

A continuaci√≥n, se muestra un fragmento de la funci√≥n que identifica las monedas utilizando la transformada de Hough y un filtro Gaussian Blur:

```python
def identificar_moneda(dir_img, moneda, todas):
    cont = 0
    total_valor = 0.0
    
    img = cv2.imread(dir_img)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Conversi√≥n a escala de grises y suavizado
    gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    pimg = cv2.GaussianBlur(gris, (5, 5), 1)
    
    # Detecci√≥n de c√≠rculos
    circ = cv2.HoughCircles(
        pimg, 
        cv2.HOUGH_GRADIENT, 
        dp=1, 
        minDist=80, 
        param1=70, 
        param2=70, 
        minRadius=0, 
        maxRadius=100
    )
```

Sin embargo, al probar en otros casos, se producen efectos no deseados, como se muestra en las siguientes im√°genes:

<div align="center">
   <img src="imagenes/moneda3.png" width="180" height="300">
   <img src="imagenes/moneda4.png" width="180" height="300">
</div>

El resultado de la imagen de la izquierda fue:

- N√∫mero de monedas: 7
- Valor total: 7,40 ‚Ç¨

El resultado de la imagen de la derecha fue:

- N√∫mero de monedas: 39
- Valor total: 8,81 ‚Ç¨

> [!TIP]  
> Como se puede observar, estos resultados no coinciden con las im√°genes mostradas, indicando que el sistema presenta errores. Por ejemplo, las monedas superpuestas no se detectan correctamente, y los valores calculados pueden ser excesivos o no representar la realidad. Por lo tanto, se evaluar√° la implementaci√≥n de un modelo m√°s preciso para mejorar la detecci√≥n y el c√°lculo.

La √∫ltima mejora implementada para detectar las monedas, especialmente las que est√°n superpuestas, consisti√≥ en optimizar la transformada de Hough y ajustar el algoritmo original. Se utiliz√≥ el radio esperado de cada moneda con una cierta tolerancia para comparar el radio detectado, lo que permiti√≥ desarrollar un modelo m√°s preciso, como se muestra en las siguientes im√°genes:

<div align="center">
   <img src="imagenes/moneda5.png" width="580" height="300">
</div>

El resultado obtenido fue:

Se detectaron 6 c√≠rculos en la imagen.
- Centro (p√≠xeles): (1740, 1894)
- Radio (p√≠xeles): 94
- Di√°metro (p√≠xeles): 188
Monedas:
- 1 euro
- 0.50 c√©ntimos
- 0.20 c√©ntimos
- 1 euro
Total: 2.7 ‚Ç¨

<div align="center">
   <img src="imagenes/moneda6.png" width="580" height="300">
</div>

El resultado obtenido fue:

Se detectaron 12 c√≠rculos en la imagen.
- Centro (p√≠xeles): (1736, 1606)
- Radio (p√≠xeles): 106
- Di√°metro (p√≠xeles): 212
- Radio seleccionado: 106
Monedas:
- 0.20 c√©ntimos
- 0.20 c√©ntimos
- 1 euro
- 0.10 c√©ntimos
- 0.02 c√©ntimos
- 0.50 c√©ntimos
- 0.50 c√©ntimos
Total: 2.52 ‚Ç¨

> [!IMPORTANT]  
> Aunque este modelo no es completamente preciso, es mucho m√°s eficiente, logrando detectar monedas superpuestas y acercarse al valor real de las monedas en diferentes fotos, incluso en situaciones complejas y desfavorables.

A continuaci√≥n, se muestra un fragmento del c√≥digo que se encarga de identificar las monedas:

```python
    def identify_coin(self, moneda=None, todas=True):
        """Identifica y suma el valor de las monedas detectadas."""
        if self.circles is None:
            print("No hay c√≠rculos detectados para identificar.")
            return

        suma = 0.0
        tolerancia = 2.25  # Tolerancia para la identificaci√≥n de monedas

        if self.selected_circle is None:
            print("No se ha seleccionado ning√∫n c√≠rculo.")
            return

        radio_seleccionado = self.selected_circle[2]
        print(f"Radio seleccionado: {radio_seleccionado}")

        coin_values = [
            {"name": "0.01", "factor": 8.13},
            {"name": "0.02", "factor": 9.375},
            {"name": "0.05", "factor": 10.625},
            {"name": "0.10", "factor": 9.875},
            {"name": "0.20", "factor": 11.125},
            {"name": "0.50", "factor": 12.125},
            {"name": "1", "factor": 11.625},
            {"name": "2", "factor": 12.875},
        ]

        for det in self.circles[0]:
            _, _, det_radio = det
            for coin in coin_values:
                expected_radius = (coin["factor"] * radio_seleccionado) / 11.625
                if abs(det_radio - expected_radius) <= tolerancia:
                    value = float(coin["name"])
                    if (moneda == coin["name"] or todas):
                        suma += value
                        print(f"{coin['name']} c√©ntimos" if value < 1 else f"{int(value)} euro{'s' if value > 1 else ''}")
                    break  
```

Gracias a este enfoque, se obtiene una aproximaci√≥n m√°s precisa en el c√°lculo del valor total de las monedas en condiciones del mundo real.


### Tarea 2 Detectar microplasticos

Para la segunda tarea, se proporcionan tres subim√°genes de tres clases de micropl√°sticos recogidos en playas canarias. La tarea propuesta consiste en determinar patrones en sus caracter√≠sticas geom√©tricas que puedan permitir su clasificaci√≥n en dichas im√°genes y otras. Como fuente de partida, se proporciona enlace al trabajo [SMACC: A System for Microplastics Automatic Counting and Classification](https://doi.org/10.1109/ACCESS.2020.2970498) en el que se adoptan algunas propiedades geom√©tricas para dicho fin. De forma resumida, las caracter√≠sticas geom√©tricas utilizadas en dicho trabajo fueron:

- √Årea en p√≠xeles
- Per√≠metro en p√≠xeles
- Compacidad (relaci√≥n del cuadrado del per√≠metro con el √°rea)
- Relaci√≥n del √°rea con la del contenedor
- Relaci√≥n del ancho y el alto del contenedor
- Relaci√≥n entre los ejes de la elipse ajustada
- Definido el centroide, relaci√≥n entre las distancias menor y mayor al contorno

## Explicaci√≥n

Para completar esta tarea se ha utilizado un modelo SVC predictivo sin redes neuronales. El funcionamiento de este modelo es simple y el procedimiento que se sigui√≥ fue el siguiente:
   - En primer lugar se entren√≥ al modelo SVC con datos de las im√°genes de prueba, estas im√°genes son las denominadas FRA, PEL y TAR. El entrenamiento consiste en umbralizar las im√°genes para segmentar las part√≠culas del fondo extrayendo posteriormente datos relevantes como su √°rea, per√≠metro, f1score (relaci√≥n altura/anchura), media del color. Tras obtener el modelo los datos de todos los ejemplos posibles (FRA, PEL y TAR) se le manda las im√°genes de test para que prediga qu√© tipo es. A continuaci√≥n se muestran los contornos que detecta el modelo durante el an√°lisis de las part√≠culas.


<table>
    <td width="50%">
        <img src="imagenes/contorno_1.png" width="400" height="260">
    </td>
    <td width="50%">
        <img src="imagenes/contorno_2.png" width="400" height="260">
    </td>
</table>

<table>
    <td width="50%">
        <img src="imagenes/contorno_3.png" width="400" height="260">
    </td>
    <td width="50%">
        <img src="imagenes/contorno_4.png" width="400" height="260">
    </td>
</table>

<table align="center">
    <div align="center">
        <td width="100%">
            <img src="imagenes/contorno_5.png" width="350" height="260">
        </td>
    </div>
</table>                                   


El c√≥digo se divide en las siguientes secciones:

``` python
def preprocess_and_segment(img):
    # Aplicar un filtro de mediana
    img_blur = cv2.GaussianBlur(img, (5,5), 0)

    # Aplicar umbralizaci√≥n adaptativa
    _, thresh = cv2.threshold(img_blur,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)

    # Extraer los contornos
    contours, _= cv2.findContours(thresh, cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_SIMPLE)

    # Filtrar contornos por √°rea para eliminar ruido
    contours = [c for c in contours if cv2.contourArea(c) > 100]  # Ajusta este valor seg√∫n tus datos
    
        # Visualizar contornos
    for contour in contours:
        cv2.drawContours(thresh, [contour], -1, (255, 0, 0), 2)  # Dibuja contornos en rojo   
    plt.imshow(thresh, cmap='gray')
    plt.title('Contornos detectados')
    plt.show()
    
    return contours
```
Esta funci√≥n umbraliza la imagen y extrae los contornos que ser√°n analizados para obtener datos por esta secci√≥n de c√≥digo


```python
def extract_features(contour, img_color):
    features = {}
    
    # Calcular caracter√≠sticas geom√©tricas clave
    area = cv2.contourArea(contour)
    perimeter = cv2.arcLength(contour, True)
    compactness = (perimeter ** 2) / area if area > 0 else 0

    # Usar boundingRect para calcular el aspect ratio
    _, __, w, h = cv2.boundingRect(contour)
    aspect_ratio = float(w) / h if h > 0 else 0

    # Calcular el color medio de la part√≠cula usando el contorno
    mask = np.zeros(img_color.shape[:2], dtype=np.uint8)  # Crear una m√°scara en blanco
    cv2.drawContours(mask, [contour], -1, 255, -1)  # Dibujar el contorno en la m√°scara
    mean_color = cv2.mean(img_color, mask=mask)  # Obtener el color medio (BGR)
    
    isBlack = 1 if ((mean_color[0] + mean_color[1] + mean_color[2]) // 3) <= 30 else 0 
    # Guardar las caracter√≠sticas clave, incluyendo el color medio
    features['area'] = area
    features['perimeter'] = perimeter
    features['compactness'] = compactness
    features['aspect_ratio'] = aspect_ratio
    features['mean_color_B'] = isBlack

    # Retornar todas las caracter√≠sticas como un array plano
    return list(features.values())
```

La √∫ltima funci√≥n que se usa en el c√≥digo es la que se toma cuando se prueba el modelo tras haber sido entrenado y esa funci√≥n es:

```python
# Funci√≥n para clasificar part√≠culas y evaluar el resultado
def classify_and_evaluate(X_train, y_train, X_test, y_test):
    # Usar imputer para manejar valores NaN
    imputer = SimpleImputer(strategy='mean')
    X_train = imputer.fit_transform(X_train)
    X_test = imputer.transform(X_test)
    
    # Crear y entrenar el modelo SVM
    model = SVC()
    model.fit(X_train, y_train)

    # Hacer predicciones
    y_pred = model.predict(X_test)

    # Mostrar el n√∫mero de part√≠culas clasificadas en cada clase
    unique, counts = np.unique(y_pred, return_counts=True)

    # Evaluar el rendimiento del modelo usando las m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
    f1score = f1_score(y_test, y_pred, average='weighted', zero_division=0)

    print(f"Accuracy: {accuracy:.2f}")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1 Score: {f1score:.2f}")

    # Matriz de confusi√≥n
    conf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8,8))
    sns.set(font_scale = 1.75)#tama√±os tipograf√≠a
    sns.set(font_scale = 3.0)

    ax = sns.heatmap(
            conf_matrix, # confusion matrix 2D array 
            annot=True, # Muestra n√∫meros en las celdas
            fmt='d', # valores enteros
            cbar=False, # sin barra de colores
            cmap='flag', # mapa de colores
            #vmax=175 # contraste de color
        )

    #Etiquetas matriz de confusi√≥n
    label_font = {'size':'25'}
    ax.set_xlabel("Predicha", labelpad=-0.75, fontdict=label_font)
    ax.set_ylabel("Real/Anotado", labelpad=20, fontdict=label_font)
    
    #print("Matriz de confusi√≥n:")
    #print(conf_matrix)
    print("------------------------------------------")
```

El segmento de c√≥digo que cohesiona estas funciones es: 

```python
# Zona entrenamiento
image_paths_train = ["FRA.png", "PEL.png", "TAR.png"]
labels_train = [1, 2, 3]
X_train = []
y_train = []

for img_path, label in zip(image_paths_train, labels_train):
    # Leer la imagen en escala de grises
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    contours = preprocess_and_segment(img)
    for contour in contours:
        features = extract_features(contour, img)
        if not any(np.isnan(features)) and not any(np.isinf(features)):
            X_train.append(features)
            y_train.append(label)

# Zona test
# Procesar la imagen de prueba
image_paths_test = ["uno.JPG", "dos.JPG", "tres.JPG"]
X_test = []
X_tests = []
y_test = [[1] * 80, [2] * 54, [3] * 54]
contador = 0

# Enmascarar la imagen, hacer un AND con la imagen original suma de los valores en promedio con el √°rea y calculo color, si no es oscuro no es 3
# Extraer caracter√≠sticas geom√©tricas de la imagen de prueba
for index in range(len(image_paths_test)):
    # Leer la imagen en escala de grises
    img = cv2.imread(image_paths_test[index], cv2.IMREAD_GRAYSCALE)
    
    # Obtener el tama√±o de la imagen
    height, width = img.shape   
    y1, y2, x1, x2 = int(0.05 * height), int(0.80 * height), int(0.15 * width), int(0.95 * width)
    
    # Imagen recortada
    img_mod = img[y1:y2, x1:x2]
    contours = preprocess_and_segment(img_mod)
    
    for contour in contours:
        # print(f'Contorno = {contour}')
        features = extract_features(contour, img)
        contador += 1
        if not any(np.isnan(list(features))) and not any(np.isinf(list(features))) and len(X_test) < len(y_test[index]): X_test.append(features)
    
    X_tests.append(X_test)
    X_test = []
    
    if len(X_tests[index]) == 0:
        print("No se encontraron part√≠culas en la imagen de prueba.")
    else:
        # Clasificar las part√≠culas y evaluar el modelo
        classify_and_evaluate(X_train, y_train, X_tests[index], y_test[index])
```

Por √∫ltimo, se adjunta la imagen que corresponde a las matriz de confusi√≥n que se generaro en la funci√≥n classify_and_evaluate(X_train, y_train, X_test, y_test)

<div align="center">
   <img src="imagenes/final_matrix_confusion.png">
</div>

---

> [!IMPORTANT]  
> Los archivos presentados aqu√≠ son una modificaci√≥n de los archivos originales de [otsedom](https://github.com/otsedom/otsedom.github.io/tree/main/VC).



---

## üìö Bibliograf√≠a

1. [Opencv](https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html)
2. [Opencv Hough circles](https://docs.opencv.org/4.x/da/d53/tutorial_py_houghcircles.html)
3. [StackOverflow how to improve accuracy](https://stackoverflow.com/questions/70659992/how-to-improve-accuracy-of-cv2s-houghcircles)
4. [Opencv tutorial Hough circle](https://docs.opencv.org/4.x/d4/d70/tutorial_hough_circle.html)
5. [THRESH OTSU OPENCV](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)
6. [Scikit-learn SVC](https://scikit-learn.org/dev/modules/generated/sklearn.svm.SVC.html)
7. [Seaborn heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html)

---

**Universidad de Las Palmas de Gran Canaria**  

EII - Grado de Ingenier√≠a Inform√°tica  
Obra bajo licencia de Creative Commons Reconocimiento - No Comercial 4.0 Internacional

---
